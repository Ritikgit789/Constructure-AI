from pydantic import BaseModel, Field
from typing import List, Optional, Dict, Any, Literal
from datetime import datetime


# ===== DOCUMENT MODELS =====

class DocumentMetadata(BaseModel):
    """Metadata for an uploaded document"""
    filename: str
    file_size: int
    upload_time: datetime
    total_pages: int
    total_text_chunks: int
    total_images: int
    document_type: Optional[str] = None  # e.g., "drawing", "specification", "schedule"


class DocumentUploadResponse(BaseModel):
    """Response after document upload"""
    document_id: str
    filename: str
    status: str
    message: str
    metadata: DocumentMetadata


class DocumentListResponse(BaseModel):
    """List of indexed documents"""
    documents: List[DocumentMetadata]
    total_count: int


# ===== CHUNK MODELS =====

class ChunkMetadata(BaseModel):
    """Metadata for a document chunk"""
    chunk_id: str
    document_id: str
    filename: str
    page_number: int
    chunk_type: Literal["text", "image", "mixed"]
    image_path: Optional[str] = None
    image_description: Optional[str] = None  # Generated by Gemini Vision


class TextChunk(BaseModel):
    """Text chunk with metadata"""
    content: str
    metadata: ChunkMetadata
    embedding: Optional[List[float]] = None


# ===== CITATION MODELS =====

class Citation(BaseModel):
    """Source citation for RAG responses"""
    source: str  # filename
    page: int
    chunk_type: Literal["text", "image", "mixed"]
    content_preview: str  # First 200 chars or image description
    relevance_score: float
    image_url: Optional[str] = None  # If chunk contains image


# ===== CHAT MODELS =====

class ChatMessage(BaseModel):
    """Single chat message"""
    role: Literal["user", "assistant", "system"]
    content: str
    timestamp: datetime = Field(default_factory=datetime.now)
    citations: Optional[List[Citation]] = None


class ChatRequest(BaseModel):
    """Request to chat endpoint"""
    message: str
    conversation_id: Optional[str] = None
    include_images: bool = True  # Whether to include image context
    max_sources: int = 5


class ChatResponse(BaseModel):
    """Response from chat endpoint"""
    conversation_id: str
    message: ChatMessage
    citations: List[Citation]
    context_used: Dict[str, Any]  # Debug info about retrieval


# ===== EXTRACTION MODELS =====

class DoorEntry(BaseModel):
    """Single door schedule entry"""
    mark: Optional[str] = None
    location: Optional[str] = None
    width_mm: Optional[int] = None
    height_mm: Optional[int] = None
    fire_rating: Optional[str] = None
    material: Optional[str] = None
    hardware: Optional[str] = None
    notes: Optional[str] = None


class DoorSchedule(BaseModel):
    """Complete door schedule extraction"""
    entries: List[DoorEntry]
    sources: List[Citation]
    total_doors: int
    extraction_confidence: float  # 0.0 - 1.0


class RoomEntry(BaseModel):
    """Single room summary entry"""
    room_number: Optional[str] = None
    room_name: Optional[str] = None
    area_sqm: Optional[float] = None
    floor_finish: Optional[str] = None
    wall_finish: Optional[str] = None
    ceiling_finish: Optional[str] = None
    notes: Optional[str] = None


class RoomSchedule(BaseModel):
    """Complete room schedule extraction"""
    entries: Optional[List["RoomEntry"]] = None
    sources: Optional[List["Citation"]] = None
    total_rooms: Optional[int] = None
    extraction_confidence: Optional[float] = None

class ExtractionRequest(BaseModel):
    """Request for structured extraction"""
    extraction_type: Literal["door_schedule", "room_schedule", "mep_equipment"]
    filter_criteria: Optional[Dict[str, Any]] = None  # e.g., {"floor": "Level 1"}


class ExtractionResponse(BaseModel):
    """Response from extraction endpoint"""
    extraction_type: str
    data: Dict[str, Any]  # DoorSchedule or RoomSchedule serialized
    sources: List[Citation]
    processing_time_seconds: float


# ===== EVALUATION MODELS =====

class TestQuery(BaseModel):
    """Test query for evaluation"""
    query_id: str
    query: str
    expected_answer_keywords: List[str]
    expected_sources: List[str]
    category: Literal["factual_qa", "extraction", "multimodal"]


class EvaluationResult(BaseModel):
    """Result of a single test query"""
    query_id: str
    query: str
    response: str
    citations: List[Citation]
    status: Literal["correct", "partial", "incorrect"]
    score: float
    notes: str


class EvaluationReport(BaseModel):
    """Complete evaluation report"""
    total_queries: int
    correct_count: int
    partial_count: int
    incorrect_count: int
    accuracy: float
    results: List[EvaluationResult]
    timestamp: datetime = Field(default_factory=datetime.now)


# ===== RETRIEVAL MODELS =====

class RetrievalResult(BaseModel):
    """Result from retrieval pipeline"""
    chunks: List[TextChunk]
    total_found: int
    retrieval_method: str
    processing_time_ms: float
